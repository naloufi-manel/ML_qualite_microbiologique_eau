{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3644deba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6d1e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Lire les données ########################################################\"\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "##############################################\n",
    "VERBOSE_VALUE = 0 # Afficher les logs d'exécution de GridSearch\n",
    "TEST_SIZE_VALUE = 0.1 # Taux du jeu de données à utiliser dans l'étape de test\n",
    "CROSS_VALID = 5 # Nombre de K pour la validation croisée\n",
    "###############################################\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"/home/manel/Bureau/BD/donnee+pluvio/smv+vdp-pluvio/donnee-sans-na/smv-vdp/seine.csv\")\n",
    "### Supprimer toutes les valeurs vides\n",
    "data = data.fillna(0) \n",
    "\n",
    "X = data.drop([\"Ecoli\",\"EI\"],axis=1)\n",
    "y = data[\"Ecoli\"]\n",
    "\n",
    "print(X)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abfe471",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################################## informations sur les données ########################################################\"\n",
    "print(\"  * * * * * * * I)  Dataframe information * * * * * * *  \")\n",
    "print(\" 1) Statistics  _  describe ()  \")\n",
    "print(data.describe())\n",
    "print(\"______________________________________\")\n",
    "print(\" 2) Informaton (Column, Non-Null, Count, Dtype)  _  info ()  \")\n",
    "print(data.info())\n",
    "\n",
    "print(\"TYPE === \",type(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse descriptive des données\n",
    "#! pip install pandas_profiling\n",
    "from pandas_profiling import ProfileReport\n",
    "prof = ProfileReport(data, title='Analyse du jeu de la Seine', html={'style':{'full_width':True}})\n",
    "prof.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57273dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################################################################################\"\n",
    "######################################## Split des données  #########################################\"\n",
    "##############################################################################################\"\n",
    "\n",
    "# Diviser les données en entrainement et test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE_VALUE, random_state=0)\n",
    "# La division est faite de manière aléatoire en divisant les données en entrainement et en test. \n",
    "# Le random state permet d'avoir une graine pour la reproductibilité. \n",
    "# Le changement de la valeur modifie la division appliquée aux données afin d'obtenir des jeux d'entrainements et de tests différents. \n",
    "\n",
    "# Supprimez la colonne date du jeu d'entrainement\n",
    "X_train = X_train.drop([\"date\"],axis=1)\n",
    "\n",
    "# Créer le test de données à exporter\n",
    "DataToExport = X_test\n",
    "df_Ytest = pd.DataFrame(data=y_test.values, columns=['list'])\n",
    "\n",
    "pieces = {'x': DataToExport, 'y': df_Ytest}\n",
    "\n",
    "DataToExport = pd.concat(pieces)\n",
    "\n",
    "# Imprimer les données à exporter\n",
    "print(DataToExport)\n",
    "\n",
    "\n",
    "print(\"  * * * * * * * -- Export -- * * * * * * *  \")\n",
    "X_test.to_csv ('data_Test.csv', index = False, header=True, sep=\";\")\n",
    "DataToExport = pd.read_csv(\"data_Test.csv\", sep=\";\")\n",
    "print(type(DataToExport))\n",
    "df_Ytest = pd.DataFrame(data=y_test.values)\n",
    "DataToExport[\"Ecolireal\"] = df_Ytest\n",
    "print(\"  * * * * * * * -- DATA TEST building -- OK -- * * * * * * *  \")\n",
    "X_test = X_test.drop([\"date\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afea18e",
   "metadata": {},
   "source": [
    "### Standardisation des données\n",
    "\n",
    "La standardisation permet la mise à l'échelle avant l'entraînement. Elle sera effectuée sur les données d'entraînement afin que les modèles n'aient pas accès aux valeurs des données de test.\n",
    "Standardisation par la moyenne : Soustraire la moyenne et diviser par l'écart-type pour chaque caractéristique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer les valeurs de la moyenne et de l'écart-type\n",
    "X_train, X_test, y_train, y_test\n",
    "train_mean = X_train.mean()\n",
    "train_std = X_train.std()\n",
    "y_mean = y_train.mean()\n",
    "y_std = y_train.std()\n",
    "\n",
    "X_train = (X_train - train_mean) / train_std\n",
    "X_test = (X_test - train_mean) / train_std\n",
    "y_train = (y_train - y_mean) / y_std\n",
    "y_test = (y_test - y_mean) / y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c5a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b25cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d908a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Détermination de l'écart-type après standardisation. \n",
    "import numpy as np\n",
    "sd=np.std(y_test)\n",
    "print(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1285b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ---------------------- Imports ----------------------------------------------------------------------\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "#Créer la grille de paramètres basée sur les résultats de la recherche aléatoire.\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "##############################################################################################\"\n",
    "######################################## MODEL KNN Split  ####################################\"\n",
    "##############################################################################################\"\n",
    "\n",
    "\n",
    "## --- Local Params\n",
    "modelName = \"KNN\"\n",
    "MethodID = \"A\"\n",
    "\n",
    "print( \" ################# ------------- ########################## \")\n",
    "print( \"Model \" ,modelName,\" is runing ........ !  \")\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "param_gridKNN = {'n_neighbors': np.arange(1, 30, 2),\n",
    "              'weights': ['uniform', 'distance']\n",
    "         }\n",
    "\n",
    "\n",
    "# Sélection du meilleur modèle\n",
    "modelKNN =  KNeighborsRegressor()\n",
    "best_model_searchKNN = GridSearchCV(estimator = modelKNN, param_grid = param_gridKNN, cv = CROSS_VALID,\n",
    "                           verbose = VERBOSE_VALUE)\n",
    "best_model_searchKNN.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#  Montrer quel est le meilleur modèle\n",
    "best_grid = best_model_searchKNN.best_estimator_\n",
    "print(\"  ------------------------------------  \")\n",
    "print (MethodID+\"-1) BEST Configuration (\"+modelName+\") is  ==== \",best_grid )\n",
    "print(\"  ------------------------------------  \")\n",
    "\n",
    "\n",
    "# prédire les valeurs en utilisant le meilleur modèle\n",
    "Y_pred_KNN = best_model_searchKNN.predict(X_test)\n",
    "Y=y_test\n",
    "num_data = X.shape[0]\n",
    "\n",
    "\n",
    "# Erreurs pour l'évaluation des performances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "mse = mean_squared_error(Y,Y_pred_KNN)\n",
    "rmse = math.sqrt(mse)\n",
    "rse = math.sqrt(mse/(num_data-2))\n",
    "mae=mean_absolute_error(Y,Y_pred_KNN)\n",
    "\n",
    "print(MethodID+\"-2) Evaluation  \"+modelName+\" Results : \")\n",
    "print(\"--> RMSE ((\"+modelName+\"))=\",rmse)\n",
    "print(\"--> MAE ((\"+modelName+\"))=\",mae)\n",
    "r = scipy.stats.pearsonr(Y,Y_pred_KNN)\n",
    "print(\"--> Pearson Correlation ((\"+modelName+\"))=\",r)\n",
    "\n",
    "\n",
    "# Exporter le modèle\n",
    "import pickle\n",
    "filename = 'bestModel'+modelName+'-pluvio-vdp-nrml-Ecoli.pickle'\n",
    "pickle.dump(best_model_searchKNN, open(filename, 'wb'))\n",
    "print(\"  ------------------------------------  \")\n",
    "print( MethodID+\"-3) Model \" ,modelName,\" is generated and exported -- OK --  \")\n",
    "print( \" ################# ------------- ########################## \")\n",
    "\n",
    "\n",
    "# Destandardisation des valeurs prédites\n",
    "Y_pred_KNN = (Y_pred_KNN*y_std)+ y_mean\n",
    "DataToExport[\"KNN_Ecoli_pred\"] = Y_pred_KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1bf486",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\"\n",
    "######################################## MODEL RF  Split  ####################################\"\n",
    "##############################################################################################\"\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "## --- Local Params\n",
    "modelName = \"RF\"\n",
    "MethodID = \"B\"\n",
    "\n",
    "print( \" ################# ------------- ########################## \")\n",
    "print( \"Model \" ,modelName,\" is runing ........ !  \")\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "param_gridRF = {\n",
    "    'bootstrap': [True],\n",
    "    'max_features': [2,3,4,5,6,7,8],\n",
    "    'n_estimators': [10, 50, 200]\n",
    "}\n",
    "\n",
    "\n",
    "# Sélection du meilleur modèle\n",
    "modelRF =  RandomForestRegressor()\n",
    "best_model_searchRF = GridSearchCV(estimator = modelRF, param_grid = param_gridRF, cv = CROSS_VALID,\n",
    "                           verbose = VERBOSE_VALUE)\n",
    "best_model_searchRF.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Montrer quel est le meilleur modèle\n",
    "best_grid = best_model_searchRF.best_estimator_\n",
    "print(\"  ------------------------------------  \")\n",
    "print (MethodID+\"-1) BEST Configuration (\"+modelName+\") is  ==== \",best_grid )\n",
    "print(\"  ------------------------------------  \")\n",
    "\n",
    "\n",
    "# Prédire les valeurs en utilisant le : best_model\n",
    "Y_pred_RF = best_model_searchRF.predict(X_test)\n",
    "Y=y_test\n",
    "num_data = X.shape[0]\n",
    "\n",
    "\n",
    "# Erreurs pour l'évaluation des performances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "mse = mean_squared_error(Y,Y_pred_RF)\n",
    "rmse = math.sqrt(mse)\n",
    "rse = math.sqrt(mse/(num_data-2))\n",
    "mae=mean_absolute_error(Y,Y_pred_RF)\n",
    "\n",
    "print(MethodID+\"-2) Evaluation  \"+modelName+\" Results : \")\n",
    "print(\"--> RMSE ((\"+modelName+\"))=\",rmse)\n",
    "print(\"--> MAE ((\"+modelName+\"))=\",mae)\n",
    "r = scipy.stats.pearsonr(Y,Y_pred_RF)\n",
    "print(\"--> Pearson Correlation ((\"+modelName+\"))=\",r)\n",
    "\n",
    "\n",
    "# Exporter le modèle\n",
    "import pickle\n",
    "filename = 'bestModel'+modelName+'-pluvio-vdp-nrml-Ecoli.pickle'\n",
    "pickle.dump(best_model_searchRF, open(filename, 'wb'))\n",
    "print(\"  ------------------------------------  \")\n",
    "print( MethodID+\"-3) Model \" ,modelName,\" is generated and exported -- OK --  \")\n",
    "print( \" ################# ------------- ########################## \")\n",
    "\n",
    "# Destandardisation des valeurs prédites\n",
    "Y_pred_RF = (Y_pred_RF*y_std)+ y_mean\n",
    "DataToExport[\"RF_Ecoli_pred\"] = Y_pred_RF\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd75d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################################################################################\"\n",
    "######################################## MODEL DT  Split  ####################################\"\n",
    "####################################### Arbre de decision ####################################\"\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "## --- Local Params\n",
    "modelName = \"DT\"\n",
    "MethodID = \"C\"\n",
    "\n",
    "print( \" ################# ------------- ########################## \")\n",
    "print( \"Model \" ,modelName,\" is runing ........ !  \")\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "param_gridDT = {\"max_depth\": [1, 2, 10, 100],\n",
    "              \"random_state\":[1, 2, 10, 100],\n",
    "              \"min_samples_leaf\":[1, 2, 10, 100]\n",
    "         }\n",
    "\n",
    "\n",
    "# Sélection du meilleur modèle\n",
    "modelDT =  tree.DecisionTreeRegressor()\n",
    "best_model_searchDT = GridSearchCV(estimator = modelDT, param_grid = param_gridDT, cv = CROSS_VALID,\n",
    "                           verbose = VERBOSE_VALUE)\n",
    "best_model_searchDT.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#  Montrer quel est le meilleur modèle\n",
    "best_grid = best_model_searchDT.best_estimator_\n",
    "print(\"  ------------------------------------  \")\n",
    "print (MethodID+\"-1) BEST Configuration (\"+modelName+\") is  ==== \",best_grid )\n",
    "print(\"  ------------------------------------  \")\n",
    "\n",
    "\n",
    "# Prédire les valeurs en utilisant best_model\n",
    "Y_pred_DT = best_model_searchDT.predict(X_test)\n",
    "Y=y_test\n",
    "num_data = X.shape[0]\n",
    "\n",
    "\n",
    "# erreurs pour l'évaluation des performances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "mse = mean_squared_error(Y,Y_pred_DT)\n",
    "rmse = math.sqrt(mse)\n",
    "rse = math.sqrt(mse/(num_data-2))\n",
    "mae=mean_absolute_error(Y,Y_pred_DT)\n",
    "\n",
    "print(MethodID+\"-2) Evaluation  \"+modelName+\" Results : \")\n",
    "print(\"--> RMSE ((\"+modelName+\"))=\",rmse)\n",
    "print(\"--> MAE ((\"+modelName+\"))=\",mae)\n",
    "r = scipy.stats.pearsonr(Y,Y_pred_DT)\n",
    "print(\"--> Pearson Correlation ((\"+modelName+\"))=\",r)\n",
    "\n",
    "\n",
    "# Exporter le modèle\n",
    "import pickle\n",
    "filename = 'bestModel'+modelName+'-pluvio-vdp-nrml-Ecoli.pickle'\n",
    "pickle.dump(best_model_searchDT, open(filename, 'wb'))\n",
    "print(\"  ------------------------------------  \")\n",
    "print( MethodID+\"-3) Model \" ,modelName,\" is generated and exported -- OK --  \")\n",
    "print( \" ################# ------------- ########################## \")\n",
    "\n",
    "# Déstandardisation des valeurs prédites\n",
    "Y_pred_DT = (Y_pred_DT*y_std)+ y_mean\n",
    "DataToExport[\"DT_Ecoli_pred\"] = Y_pred_DT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d4ef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\"\n",
    "######################################## MODEL SVM  Split  ####################################\"\n",
    "################################ Machine a vecteurs de support  ###############################\"\n",
    "######################################### non lineaire ########################################\"\n",
    " \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "## --- Local Params\n",
    "modelName = \"SVM\"\n",
    "MethodID = \"D\"\n",
    "\n",
    "print( \" ################# ------------- ########################## \")\n",
    "print( \"Model \" ,modelName,\" is runing ........ !  \")\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "param_gridSVM = {'kernel' : ('sigmoid', 'rbf'),\n",
    "         'coef0' : [0.01,10,0.5],\n",
    "         'gamma' : ('auto','scale')\n",
    "         }\n",
    "\n",
    "\n",
    "# Sélection du meilleur modèle\n",
    "modelSVM = SVR()\n",
    "best_model_searchSVM = GridSearchCV(estimator = modelSVM, param_grid = param_gridSVM, cv = CROSS_VALID,\n",
    "                           verbose = VERBOSE_VALUE)\n",
    "best_model_searchSVM.fit(X_train,y_train)\n",
    "\n",
    "#  Show which is the best model\n",
    "best_grid = best_model_searchSVM.best_estimator_\n",
    "print(\"  ------------------------------------  \")\n",
    "print (MethodID+\"-1) BEST Configuration (\"+modelName+\") is  ==== \",best_grid )\n",
    "print(\"  ------------------------------------  \")\n",
    "\n",
    "#  Montrer quel est le meilleur modèle\n",
    "Y_pred_SVM = best_model_searchSVM.predict(X_test)\n",
    "Y=y_test\n",
    "num_data = X.shape[0]\n",
    "\n",
    "\n",
    "# Prédire les valeurs en utilisant best_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "mse = mean_squared_error(Y,Y_pred_SVM)\n",
    "rmse = math.sqrt(mse)\n",
    "rse = math.sqrt(mse/(num_data-2))\n",
    "mae=mean_absolute_error(Y,Y_pred_SVM)\n",
    "\n",
    "print(MethodID+\"-2) Evaluation  \"+modelName+\" Results : \")\n",
    "print(\"--> RMSE ((\"+modelName+\"))=\",rmse)\n",
    "print(\"--> MAE ((\"+modelName+\"))=\",mae)\n",
    "r = scipy.stats.pearsonr(Y,Y_pred_SVM)\n",
    "print(\"--> Pearson Correlation ((\"+modelName+\"))=\",r)\n",
    "\n",
    "\n",
    "# Export the model\n",
    "import pickle\n",
    "filename = 'bestModel'+modelName+'-pluvio-vdp-nrml-Ecoli.pickle'\n",
    "pickle.dump(best_model_searchSVM, open(filename, 'wb'))\n",
    "print(\"  ------------------------------------  \")\n",
    "print( MethodID+\"-3) Model \" ,modelName,\" is generated and exported -- OK --  \")\n",
    "print( \" ################# ------------- ########################## \")\n",
    "\n",
    "\n",
    "# Destandardisation des valeurs prédites \n",
    "Y_pred_SVM = (Y_pred_SVM*y_std)+ y_mean\n",
    "DataToExport[\"SVM_Ecoli_pred\"] = Y_pred_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c537ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\"\n",
    "######################################## MODEL AdaBoost  Split  ####################################\"\n",
    "##############################################################################################\"\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "## --- Local Params\n",
    "modelName = \"AdaBoost\"\n",
    "MethodID = \"E\"\n",
    "\n",
    "print( \" ################# ------------- ########################## \")\n",
    "print( \"Model \" ,modelName,\" is runing ........ !  \")\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "param_gridADaBoost = {'base_estimator__min_samples_leaf':[1,2, 5],\n",
    "              \"learning_rate\": [0.2,0.5],\n",
    "              \"n_estimators\": [20, 50, 100]\n",
    "         }\n",
    "\n",
    "\n",
    "# Sélection du meilleur modèle\n",
    "from sklearn import tree\n",
    "DTC = tree.DecisionTreeRegressor(random_state = 11, max_features = \"auto\",\n",
    "                                 max_depth = None)\n",
    "ModelAdaBoostDTC = AdaBoostRegressor(base_estimator = DTC)\n",
    "best_model_searchAdaBoost = GridSearchCV(estimator = ModelAdaBoostDTC, param_grid = param_gridADaBoost, cv = CROSS_VALID,\n",
    "                           verbose = VERBOSE_VALUE)\n",
    "best_model_searchAdaBoost.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#  Montrer quel est le meilleur modèle\n",
    "best_grid = best_model_searchAdaBoost.best_estimator_\n",
    "print(\"  ------------------------------------  \")\n",
    "print (MethodID+\"-1) BEST Configuration (\"+modelName+\") is  ==== \",best_grid )\n",
    "print(\"  ------------------------------------  \")\n",
    "\n",
    "\n",
    "# Prédire les valeurs en utilisant best_model\n",
    "Y_pred_AdaBoost = best_model_searchAdaBoost.predict(X_test)\n",
    "\n",
    "Y=y_test\n",
    "num_data = X.shape[0]\n",
    "\n",
    "\n",
    "# Erreurs pour l'évaluation des performances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "mse = mean_squared_error(Y,Y_pred_AdaBoost)\n",
    "rmse = math.sqrt(mse)\n",
    "rse = math.sqrt(mse/(num_data-2))\n",
    "mae=mean_absolute_error(Y,Y_pred_AdaBoost)\n",
    "\n",
    "print(MethodID+\"-2) Evaluation  \"+modelName+\" Results : \")\n",
    "print(\"--> RMSE ((\"+modelName+\"))=\",rmse)\n",
    "print(\"--> MAE ((\"+modelName+\"))=\",mae)\n",
    "r = scipy.stats.pearsonr(Y,Y_pred_AdaBoost)\n",
    "print(\"--> Pearson Correlation ((\"+modelName+\"))=\",r)\n",
    "\n",
    "\n",
    "# Exportez le modèle\n",
    "import pickle\n",
    "filename = 'bestModel'+modelName+'-pluvio-vdp-nrml-Ecoli.pickle'\n",
    "pickle.dump(best_model_searchAdaBoost, open(filename, 'wb'))\n",
    "print(\"  ------------------------------------  \")\n",
    "print( MethodID+\"-3) Model \" ,modelName,\" is generated and exported -- OK --  \")\n",
    "print( \" ################# ------------- ########################## \")\n",
    "\n",
    "\n",
    "# Destandardisation des valeurs prédites\n",
    "Y_pred_AdaBoost = (Y_pred_AdaBoost*y_std)+ y_mean\n",
    "DataToExport[\"AdaBoost_Ecoli_pred\"] = Y_pred_AdaBoost\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f50a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\"\n",
    "######################################## MODEL Bagging avec estimator RF ####################################\"\n",
    "##############################################################################################\"\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "## --- Local Params\n",
    "modelName = \"BaggingRF\"\n",
    "MethodID = \"H\"\n",
    "\n",
    "print( \" ################# ------------- ########################## \")\n",
    "print( \"Model \" ,modelName,\" is runing ........ !  \")\n",
    "\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=100, n_features=7,n_informative=2, n_targets=1, random_state=0, shuffle=False)\n",
    "\n",
    "param_gridBag = {\n",
    "    'bootstrap': [True],\n",
    "    'max_features': [0, 7],\n",
    "    'n_estimators': [10, 50, 200]\n",
    "}\n",
    "\n",
    "\n",
    "# Sélection du meilleur modèle\n",
    "modelRF =  RandomForestRegressor()\n",
    "modelBaggingRF = BaggingRegressor(base_estimator=modelRF, n_estimators=10, random_state=0).fit(X, y) # base estimator par defaut DesicionTreeRegressor\n",
    "best_model_searchBag2 = GridSearchCV(estimator = modelBaggingRF, param_grid = param_gridBag, cv = CROSS_VALID,\n",
    "                           verbose = VERBOSE_VALUE)\n",
    "best_model_searchBag2.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#  Montrer quel est le meilleur modèle\n",
    "best_grid = best_model_searchBag2.best_estimator_\n",
    "print(\"  ------------------------------------  \")\n",
    "print (MethodID+\"-1) BEST Configuration (\"+modelName+\") is  ==== \",best_grid )\n",
    "print(\"  ------------------------------------  \")\n",
    "\n",
    "\n",
    "# Prédire les valeurs en utilisant best_model\n",
    "Y_pred_Bag2 = best_model_searchBag2.predict(X_test)\n",
    "Y=y_test\n",
    "num_data = X.shape[0]\n",
    "\n",
    "\n",
    "# Erreurs pour l'évaluation des performances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "mse = mean_squared_error(Y,Y_pred_Bag2)\n",
    "rmse = math.sqrt(mse)\n",
    "rse = math.sqrt(mse/(num_data-2))\n",
    "mae=mean_absolute_error(Y,Y_pred_Bag2)\n",
    "\n",
    "print(MethodID+\"-2) Evaluation  \"+modelName+\" Results : \")\n",
    "print(\"--> RMSE ((\"+modelName+\"))=\",rmse)\n",
    "print(\"--> MAE ((\"+modelName+\"))=\",mae)\n",
    "r = scipy.stats.pearsonr(Y,Y_pred_Bag2)\n",
    "print(\"--> Pearson Correlation ((\"+modelName+\"))=\",r)\n",
    "\n",
    "\n",
    "# Exportez le modèle\n",
    "import pickle\n",
    "filename = 'bestModel'+modelName+'-pluvio-vdp-nrml-Ecoli.pickle'\n",
    "pickle.dump(best_model_searchBag2, open(filename, 'wb'))\n",
    "print(\"  ------------------------------------  \")\n",
    "print( MethodID+\"-3) Model \" ,modelName,\" is generated and exported -- OK --  \")\n",
    "print( \" ################# ------------- ########################## \")\n",
    "\n",
    "\n",
    "# Destandardisation des valeurs prédites\n",
    "Y_pred_Bag2 = (Y_pred_Bag2*y_std)+ y_mean\n",
    "DataToExport[\"Bagging_Ecoli_pred\"] = Y_pred_Bag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0c10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les données à exporter\n",
    "DataToExport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f58c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## prédictions pour la Marne ########################################################\"\n",
    "\n",
    "# Lire les données de la Marne\n",
    "data2 = pd.read_csv(\"/home/manel/Bureau/BD/donnee+pluvio/smv+vdp-pluvio/donnee-sans-na/smv-vdp/smv2.csv\")\n",
    "X_test2 = data2.drop([\"Ecoli\",\"EI\"],axis=1)\n",
    "y_test2 = data2[\"Ecoli\"]\n",
    "X_test2 = X_test2.drop([\"date\"],axis=1)\n",
    "\n",
    "# Standardisation des données de la seine \n",
    "X_test2 = (X_test2 - train_mean) / train_std\n",
    "y_test2 = (y_test2 - y_mean) / y_std\n",
    "\n",
    "# Importé les différents modèles générés précédemment\n",
    "import pickle\n",
    "loaded_model_knn=pickle.load(open('bestModelKNN-pluvio-vdp-nrml-Ecoli.pickle', 'rb'))\n",
    "loaded_model_rf=pickle.load(open('bestModelRF-pluvio-vdp-nrml-Ecoli.pickle', 'rb'))\n",
    "loaded_model_dt=pickle.load(open('bestModelDT-pluvio-vdp-nrml-Ecoli.pickle', 'rb'))\n",
    "loaded_model_svm=pickle.load(open('bestModelSVM-pluvio-vdp-nrml-Ecoli.pickle', 'rb'))\n",
    "loaded_model_adaboost=pickle.load(open('bestModelAdaBoost-pluvio-vdp-nrml-Ecoli.pickle', 'rb'))\n",
    "loaded_model_bagging=pickle.load(open('bestModelBaggingRF-pluvio-vdp-nrml-Ecoli.pickle', 'rb'))\n",
    "\n",
    "\n",
    "### Prédiction avec le modèle KNN\n",
    "Y_pred_KNN = loaded_model_knn.predict(X_test2)\n",
    "\n",
    "# Erreurs pour l'évaluation des performances\n",
    "mse = mean_squared_error(y_test2,Y_pred_KNN)\n",
    "rmse = math.sqrt(mse)\n",
    "print('knn')\n",
    "print(\"--> RMSE knn=\",rmse)\n",
    "mae=mean_absolute_error(y_test2,Y_pred_KNN)\n",
    "print(\"--> MAE knn=\",mae)\n",
    "r = scipy.stats.pearsonr(y_test2,Y_pred_KNN)\n",
    "print(\"--> Pearson Correlation knn=\",r)\n",
    "\n",
    "# Destandardisation des valeurs prédites\n",
    "Y_pred_KNN = (Y_pred_KNN*y_std)+ y_mean\n",
    "data2[\"knn\"] = Y_pred_KNN\n",
    "\n",
    "\n",
    "### Prédiction avec le modèle RF\n",
    "Y_pred_rf = loaded_model_rf.predict(X_test2)\n",
    "\n",
    "# Erreurs pour l'évaluation des performances\n",
    "mse = mean_squared_error(y_test2,Y_pred_rf)\n",
    "rmse = math.sqrt(mse)\n",
    "print('rf')\n",
    "print(\"--> RMSE rf=\",rmse)\n",
    "mae=mean_absolute_error(y_test2,Y_pred_rf)\n",
    "print(\"--> MAE rf=\",mae)\n",
    "r = scipy.stats.pearsonr(y_test2,Y_pred_rf)\n",
    "print(\"--> Pearson Correlation rf=\",r)\n",
    "\n",
    "# Destandardisation des valeurs prédites\n",
    "Y_pred_rf = (Y_pred_rf*y_std)+ y_mean\n",
    "data2[\"rf\"] = Y_pred_rf\n",
    "\n",
    "\n",
    "### Prédiction avec le modèle DT\n",
    "Y_pred_dt = loaded_model_dt.predict(X_test2)\n",
    "\n",
    "# Erreurs pour l'évaluation des performances\n",
    "mse = mean_squared_error(y_test2,Y_pred_dt)\n",
    "rmse = math.sqrt(mse)\n",
    "print('dt')\n",
    "print(\"--> RMSE dt=\",rmse)\n",
    "mae=mean_absolute_error(y_test2,Y_pred_dt)\n",
    "print(\"--> MAE dt=\",mae)\n",
    "r = scipy.stats.pearsonr(y_test2,Y_pred_dt)\n",
    "print(\"--> Pearson Correlation dt=\",r)\n",
    "\n",
    "# Destandardisation des valeurs prédites\n",
    "Y_pred_dt = (Y_pred_dt*y_std)+ y_mean\n",
    "data2[\"dt\"] = Y_pred_dt\n",
    "\n",
    "\n",
    "### Prédiction avec le modèle SVM\n",
    "Y_pred_svm = loaded_model_svm.predict(X_test2)\n",
    "\n",
    "# Erreurs pour l'évaluation des performances\n",
    "mse = mean_squared_error(y_test2,Y_pred_svm)\n",
    "rmse = math.sqrt(mse)\n",
    "print('svm')\n",
    "print(\"--> RMSE svm =\",rmse)\n",
    "mae=mean_absolute_error(y_test2,Y_pred_svm)\n",
    "print(\"--> MAE svm=\",mae)\n",
    "r = scipy.stats.pearsonr(y_test2,Y_pred_svm)\n",
    "print(\"--> Pearson Correlation svm=\",r)\n",
    "\n",
    "# Destandardisation des valeurs prédites\n",
    "Y_pred_svm = (Y_pred_svm*y_std)+ y_mean\n",
    "data2[\"svm\"] = Y_pred_svm\n",
    "\n",
    "\n",
    "### Prédiction avec le modèle AdaBoost\n",
    "Y_pred_adaboost = loaded_model_adaboost.predict(X_test2)\n",
    "\n",
    "# Erreurs pour l'évaluation des performances\n",
    "mse = mean_squared_error(y_test2,Y_pred_adaboost)\n",
    "rmse = math.sqrt(mse)\n",
    "print('adaboost')\n",
    "print(\"--> RMSE  adaboost =\",rmse)\n",
    "mae=mean_absolute_error(y_test2,Y_pred_adaboost)\n",
    "print(\"--> MAE adaboost=\",mae)\n",
    "r = scipy.stats.pearsonr(y_test2,Y_pred_adaboost)\n",
    "print(\"--> Pearson Correlation adaboost=\",r)\n",
    "\n",
    "# Destandardisation des valeurs prédites\n",
    "Y_pred_adaboost = (Y_pred_adaboost*y_std)+ y_mean\n",
    "data2[\"adaboost\"] = Y_pred_adaboost\n",
    "\n",
    "\n",
    "### Prédiction avec le modèle Bagging\n",
    "Y_pred_bagging = loaded_model_bagging.predict(X_test2)\n",
    "\n",
    "# Erreurs pour l'évaluation des performances\n",
    "mse = mean_squared_error(y_test2,Y_pred_bagging)\n",
    "rmse = math.sqrt(mse)\n",
    "print('adaboost')\n",
    "print(\"--> RMSE  bagging =\",rmse)\n",
    "mae=mean_absolute_error(y_test2,Y_pred_bagging)\n",
    "print(\"--> MAE bagging=\",mae)\n",
    "r = scipy.stats.pearsonr(y_test2,Y_pred_bagging)\n",
    "print(\"--> Pearson Correlation bagging=\",r)\n",
    "\n",
    "# Destandardisation des valeurs prédites\n",
    "Y_pred_bagging = (Y_pred_bagging*y_std)+ y_mean\n",
    "data2[\"bagging\"] = Y_pred_bagging\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6de9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Détermination de l'écart-type sur les données de la Marne.\n",
    "import numpy as np\n",
    "sd=np.std(y_test2)\n",
    "print(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343950bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Exporter les données   ####################################\"\n",
    "\n",
    "# Exporter les données avec les valeurs de prédiction pour tous les modèles \n",
    "print( \" ======================================================= \")\n",
    "print( \" ======================================================= \")\n",
    "\n",
    "print(\"  * * * * * * * IV) Export CSV  * * * * * * *  \")\n",
    "DataToExport.to_csv ('/home/manel/Bureau/BD/donnee+pluvio/smv+vdp-pluvio/donnee-sans-na/smv-vdp/ML/train_vdp/data_prediValuesML_ecoli_seine_seed0.csv', index = False, header=True, sep=\";\")\n",
    "data2.to_csv ('/home/manel/Bureau/BD/donnee+pluvio/smv+vdp-pluvio/donnee-sans-na/smv-vdp/ML/train_vdp/data_prediValuesML_ecoli_smv_seed0.csv', index = False, header=True, sep=\";\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aea707",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\"\n",
    "################################### Analyser le modèle RF  ####################################\"\n",
    "##############################################################################################\"\n",
    "\n",
    "#! pip install treeinterpreter\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "\n",
    "rf = RandomForestRegressor(max_features=8, n_estimators=200)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "prediction, bias, contributions = ti.predict(rf, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb23e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, bias, contributions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
